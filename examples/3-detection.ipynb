{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTW dataset tutorial (Part 3: Detection baseline)\n",
    "\n",
    "In this part of the turotial, we will show you:\n",
    "\n",
    "  - [Framework of detection baseline](#Framework-of-detection-baseline)\n",
    "  - [Training steps](#Training-steps)\n",
    "  - [Predicting steps](#Training-steps)\n",
    "  - [Results format and evaluation API](#Results-format-and-evaluation-API)\n",
    "  - [Evaluate results locally](#Evaluate-results-locally)\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > This notebook MUST be run under `$CTW_ROOT/examples`.\n",
    "  >\n",
    "  > All our code SHOULD run on `Linux>=3` with `Python>=3.4`. We make it compatible with `Python>=2.7` with best effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework of detection baseline\n",
    "\n",
    "We use [YOLOv2](https://pjreddie.com/darknet/yolo/) and slightly modified it, detailed in git commits. We apply image cropping method and multiscale testing scheme, all are described in our paper.\n",
    "\n",
    "Following the classification task, we also limit the number of categories to 1001, i.e., the top 1000 frequent observed character categories and an 'others' category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps\n",
    "\n",
    "Something are similar to classification tutorial, so this tutorial is simplified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile darknet and download pre-trained model\n",
    "\n",
    "Firstly, initialize git submodules. If you have problem initializing submodules, you may manually download darknet and copy it to corresponding directory.\n",
    "\n",
    "Note that we have slightly modified darknet, so you shouldn't clone original darknet. Do clone the repository described in `$CTW_ROOT/.gitmodules` and pay attention to its `branch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!git submodule update --init --recursive\n",
    "!cd ../detection/darknet && make -j8\n",
    "!cd ../detection && if [ ! -f \"products/darknet19_448.conv.23\" ]; then curl https://pjreddie.com/media/files/darknet19_448.conv.23 -o products/darknet19_448.conv.23; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../detection && python3 decide_cates.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop images and write meta data\n",
    "\n",
    "This step will write:\n",
    "\n",
    "  - detection/products/trainval/\\*.\\{jpg,txt\\}\n",
    "  - detection/products/trainval.txt\n",
    "  - detection/products/yolo-chinese.cfg\n",
    "  - detection/products/chinese.data\n",
    "  - detection/products/chinese.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../detection && python3 prepare_train_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run train scripts\n",
    "\n",
    "This step will write:\n",
    "\n",
    "  - detection/products/backup/\\*.weights\n",
    "\n",
    "This script generates a mount of logs and takes a long time, so we recommand you to run it with `/bin/bash` instead of running it directly in jupyter notebook.\n",
    "\n",
    "Time cost estimation (NVIDIA GTX TITAN X): 3.0 sec / step, 38 hours in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../detection && python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop testing images and write meta data\n",
    "\n",
    "This step will write:\n",
    "\n",
    "  - detection/products/test/\\*.\\{jpg,txt\\}\n",
    "  - detection/products/test.txt\n",
    "  - detection/products/yolo-chinese-test.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../detection && python3 prepare_test_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run darknet\n",
    "\n",
    "You may need to `TEST_NUM_GPU` in `detection/settings.py` and `num_thread` in `detection/eval.py` before run this step. One thread takes about 3.5 GB GPU memory. If you can run $n$ threads in one GPU, you should set `num_thread` to `n * TEST_NUM_GPU` to achive maximum utilization.\n",
    "\n",
    "This step will write:\n",
    "\n",
    "  - detection/products/chinese.\\*.data\n",
    "  - detection/products/test.\\*.txt\n",
    "  - detection/products/results/chinese.\\*.txt\n",
    "\n",
    "This script generates a mount of logs and takes a long time, so we recommand you to run it with `/bin/bash` instead of running it directly in jupyter notebook.\n",
    "\n",
    "Time cost estimation (NVIDIA GTX TITAN X \\* 2): 0.2 sec * num_thread / subimage, 2.4 hours in total.\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > For validating set, which size is about 0.5 times detection testing set, time cost estimation is 1.2 hours in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../detection && python3 eval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge results\n",
    "\n",
    "We don't apply non-maximum suppression (NMS) on each of subimages in YOLOv2.\n",
    "\n",
    "1. Collect candidates from results of subimages from YOLOv2.\n",
    "2. Abandon candidates with improper size.\n",
    "3. Splice candidates on subimages to full images.\n",
    "4. Apply NMS on full images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../detection && python3 merge_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results format and evaluation API\n",
    "\n",
    "Detection results MUST be UTF-8 encoded [JSON Lines](http://jsonlines.org/), each line MUST match the corresponding item in `test_det` in overall information, which is described in `Tutorial part 1: Basics`.\n",
    "\n",
    "```\n",
    "result (corresponding to one line in .jsonl):\n",
    "{\n",
    "    detections: [detection_0, detection_1, detection_2, ...],  # length of this list MUST be less than or equal to 1000\n",
    "}\n",
    "\n",
    "detection:\n",
    "{\n",
    "    bbox: [x, y, w, h],          # x, y, w, h are floating-point numbers, and w, h MUST be greater than 0\n",
    "    text: str,                   # length is usually 1, otherwise this must be a failed detection\n",
    "    score: float,\n",
    "}\n",
    "```\n",
    "\n",
    "Our evaluation API in `pythonapi/eval_tools.py` works as follows.\n",
    "\n",
    "  1. Check the detection (DT) file has the same number of lines as the grount truth (GT) file. Otherwise, return error.\n",
    "  2. Check each line of the DT file is valid JSON, and conform to the results format. Otherwise, return error.\n",
    "  3. Use the ignore list (IG) in the annotations.\n",
    "  4. Non-Chinese character instances are removed from GT and added to IG.\n",
    "  5. For each of the sizes, we deal with DTs, GTs, and IGs of each of the images in following steps, respectively.\n",
    "    1. Move GTs which are not fit to current size range to IG. (For size 'all', this step always has no effect)\n",
    "    2. Match DTs with GTs greedily, order by 'score' of DTs in descending order firstly and order by IOU between DTs and GTs in descending order secondarily. Matched DTs are TPs.\n",
    "    3. Match DTs with IGs, matched DTs have no effect to the evaluation.\n",
    "    4. Remove DTs which are not fit to current size range. These DTs have no effect to the evaluation. (For size 'all', this step always has no effect)\n",
    "    5. Remaining DTs are FNs, Remaining GTs are FPs. Note there is no need to compute TNs.\n",
    "    6. Sort TPs and FNs of DTs order by 'score' in descending order, take top-$n$ of them as TPs of GTs.\n",
    "  6. For each size, we compute metrics in following steps, respectively.\n",
    "    1. For each character category, take TPs and FNs of DTs belong to specified category to compute AP. Compute the mean of these APs weighted by number of character instances in each category, denote this mean value as `macro-mAP`, also call it `mAP`.\n",
    "    2. For each attribute, count TPs and FPs of GTs and compute `recall`, respectively.\n",
    "    3. For each character category, count TPs and FPs of GTs and compute `recall`, respectively.\n",
    "    3. Take TPs and FNs of DTs in all categories to compute `AP`.\n",
    "    4. For each image, take TPs and FNs of DTs belong to specified image to compute AP. Compute the mean of these APs, denote this mean value as `micro-mAP`.\n",
    "\n",
    "When matching a DT with a GT, we require they have the same character category, and $IOU(DT, GT) > 0.5$. When matching a DT with a IG, we require $\\exists ig \\in IG$, s.t. $IOU(DT, ig) > 0.5$. Of which $IOU(A, B) = \\frac{Area(A \\cap B)}{Area(A \\cup B)}$.\n",
    "\n",
    "For any group of TPs and FNs of DTs, we compute AP in following steps.\n",
    "\n",
    "  1. TODO: How to compute AP\n",
    "\n",
    "If no error, the data struct for the output of evaluation API is described below.\n",
    "\n",
    "```\n",
    "TODO: output format\n",
    "```\n",
    "\n",
    "Macro-mAP (also called `mAP`) of size `all` should be considered the single most important metric on CTW.\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > Python API and C++ API may generate slightly different results due to floating-point precision, the difference is always less than 0.0000001%. We officially approve the results of C++ API.\n",
    "  >\n",
    "  > If two DTs, A and B, have the same confidence score in one image, if A is in front of B in the list, we will match A before B with GTs in greedily matching step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
