{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTW dataset tutorial (Part 2: Classification baseline)\n",
    "\n",
    "In this part of the turotial, we will show you:\n",
    "\n",
    "  - [Framework of classification baseline](#Framework-of-classification-baseline)\n",
    "  - [Training steps](#Training-steps)\n",
    "  - [Predicting steps](#Training-steps)\n",
    "  - [Results format and evaluation API](#Results-format-and-evaluation-API)\n",
    "  - [Evaluate results locally](#Evaluate-results-locally)\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > This notebook MUST be run under `$CTW_ROOT/examples`.\n",
    "  >\n",
    "  > All our code SHOULD run on `Linux>=3` with `Python>=3.4`. We make it compatible with `Python>=2.7` with best effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework of classification baseline\n",
    "\n",
    "We regard the text recoginition problem as a classification problem. We train models using [Tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "We only consider recognition of the top 1000 frequent observed character categories. We give up to recognize other categories, which must will leads a failure on those categories.\n",
    "\n",
    "The _magic number_ `1000` is written in `classification/settings.py`. You may modify it if you want to train with another number of categories.\n",
    "\n",
    "For each of the character instances, we take following operations.\n",
    "\n",
    "  1. crop the image region around it\n",
    "  2. (training step only) randomly adjust saturation, brightness, contrast\n",
    "  3. (training step only) randomly apply an affine transform\n",
    "  4. per instance standardization \n",
    "  5. resize to fit the input of classification models\n",
    "  6. feed to each of the classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > Before you run any scripts, please ensure you have requirements installed, which are described in `Tutorial part 1: Basics`.\n",
    "  >\n",
    "  > We train models on a desktop with 32 GB RAM. If your RAM is less than 32 GB, some code may fail.\n",
    "  >\n",
    "  > We train models on NVIDIA GTX TITAN X, which GPU memory is 12 GB. If your GPU memory is less than 12 GB, you may need to turn down `batch_size` in `cfgs` in `classification/train.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide categories\n",
    "Decide which categories are the top 1000 frequent observed character categories, and save to `products/cates.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../classification && python3 decide_cates.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pickles\n",
    "\n",
    "Crop the image region around character instances, and save pickles to `products/*.pkl`, in order to avoid frequently reading `.jpg` files.\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > Due to `pickle` module is not fully compatible between Python 2 and Python 3, we restrict each of all python scripts using pickle to use Python 3 with an assertion `assert six.PY3`, including following sections and other tutorials. You MAY change all of them to `assert six.PY2` if needed, but you SHOULD NOT perform a mixture use of Python 2 pickle and Python 3 pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../classification && python3 create_pkl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run train scripts\n",
    "\n",
    "Run train script with command line argument `alexnet_v2` to train `AlexNet v2`. Other choices are `overfeat`, `inception_v4`, `resnet_v2_50` and `res_net_v2_152`.\n",
    "\n",
    "Train logs and checkpoints are saved to `classification/products/train_logs_alexnet_v2/`. You can run `tensorboard` to see detailed logs.\n",
    "\n",
    "This script generates a mount of logs and takes a long time, so we recommand you to run it with `/bin/bash` instead of running it directly in jupyter notebook.\n",
    "\n",
    "Time cost estimation (NVIDIA GTX TITAN X):\n",
    "\n",
    "  - **alexnet_v2**: 0.2 sec / step, 6 hours in total\n",
    "  - **resnet_v2_152**: 1.2 sec / step, 33 hours in total\n",
    "  - **others**: 1.0 sec / step, 28 hours in total\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > If training step become slower and slower (e.g. > 2 sec / step), you can just press Ctrl+C to interrupt it, execute `sudo sh -c \"echo 3 >/proc/sys/vm/drop_caches\"` to drop caches, and rerun `train.py`. It will automatically resume from the latest checkpoint. We save checkpoints per 1200 seconds, and this can be modified by `save_interval_secs` in `cfg_common` in `classification/train.py`. Do not run it along with other memory intensive applications.\n",
    "  >\n",
    "  > If you get a `CUDNN_STATUS_BAD_PARAM` error, you may turn down `per_process_gpu_memory_fraction` in `classification/train.py`.\n",
    "  >\n",
    "  > When training `resnet_v2_152`, tensorflow run training step and summary step at the same time may run out of memory (OOM). You may set `save_summaries_secs` in `cfgs` in `classification/train.py` to infinity (e.g. 999999) to disable summary step.\n",
    "  >\n",
    "  > You can modify `cfgs` in `classification/train.py` to add or delete models. All avaliable models are described in `classification/slim/nets/nets_factory.py`, but we have not tested whether each of the models is suitable to our dataset.\n",
    "  >\n",
    "  > You can update TensorFlow-Slim from [source](https://github.com/tensorflow/models/tree/master/research/slim), but please keep our customized modified `slim/train_image_classifier.py` and `slim/eval_image_classifier.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../classification && python3 train.py alexnet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# during training, you can browse train logs using tensorboard\n",
    "!tensorboard --logdir=../classification/products/train_logs_alexnet_v2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download trained models\n",
    "\n",
    "Since training takes a lot of energy and we hate global warming, we provide the `checkpoint` trained as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting steps\n",
    "\n",
    "Just like [training steps](#Training-steps), only need to substitute `train.py` with `eval.py`.\n",
    "\n",
    "This step will feed each of the character instances in classification testing set to the model, and save the output end point (so called _logits_) of the model to `classification/products/eval_alexnet_v2.pkl`.\n",
    "\n",
    "Then, for each of the character instances, we sort the `logits`, and output the Top-5 candicates for each of character instances to `classification/products/predictions_alexnet_v2.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../classification && python3 eval.py alexnet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results format and evaluation API\n",
    "\n",
    "Classification results MUST be UTF-8 encoded [JSON Lines](http://jsonlines.org/), each line MUST match the corresponding line in `Classification testing set annotations`, which is described in `Tutorial part 1: Basics`.\n",
    "\n",
    "```\n",
    "result (corresponding to one line in .jsonl):\n",
    "{\n",
    "    predictions: [prediction_0, prediction_1, prediction_2, ...],\n",
    "}\n",
    "\n",
    "prediction:\n",
    "[candidate_0, candidate_1, candidate_2, ...]      # there MUST be at least 5 candidates\n",
    "\n",
    "candidate: str                                    # length is usually 1, otherwise this must be a failed prediction\n",
    "```\n",
    "\n",
    "Our evaluation API in `pythonapi/eval_tools.py` works as follows.\n",
    "\n",
    "  1. Check prediction (PR) file has the same number of lines as the grount truth (GT) file. Otherwise, return error.\n",
    "  2. Check each line of the PR file is valid JSON, and conform to the results format. Otherwise, return error.\n",
    "  3. Check PR provide the same number of predictions as the number of Chinese character instances in GT. Otherwise, return error.\n",
    "  4. Count the number of instances and the number of matched instances for each of attributes combination and each of sizes, respectively.\n",
    "\n",
    "If no error, the data struct for the output of evaluation API is described below.\n",
    "\n",
    "```\n",
    "output:\n",
    "{\n",
    "    error: 0,\n",
    "    performance: {\n",
    "      all: size_performance,\n",
    "      large: size_performance,\n",
    "      medium: size_performance,\n",
    "      small: size_performance,\n",
    "    }\n",
    "}\n",
    "\n",
    "size_performance:\n",
    "[attr_performance_0, attr_performance_1, attr_performance_2, ..., attr_performance_63]\n",
    "\n",
    "attr_performance:\n",
    "{\n",
    "    n: int,\n",
    "    recalls: {\n",
    "      1: int,\n",
    "      5: int,\n",
    "    }\n",
    "}  \n",
    "```\n",
    "\n",
    "`k` in `attr_performance_k` is represented in bitwise. e.g. `k = 5` (`000101` in binary) means:\n",
    "\n",
    "| Attribute | Yes or no |\n",
    "| --------- | --------- |\n",
    "| occluded  | 1 |\n",
    "| bgcomplex | 0 |\n",
    "| distorted | 1 |\n",
    "| raised    | 0 |\n",
    "| wordart   | 0 |\n",
    "| handwritten | 0 |\n",
    "\n",
    "corresponding to character instances with attributes combination `occluded & ~bgcomplex & distorted & ~raised & ~wordart & ~handwritten`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > Since our evaluation API computes both top-1 accuracy and top-5 accuracy, you MUST provide at least 5 candidates for each of the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results locally\n",
    "\n",
    "If you don't have ground truth of testing set, you cannot run following scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather statistics\n",
    "\n",
    "Run this script to gather statistics. This step will generate:\n",
    "\n",
    "  - `judge/products/stat_frequency.json`: the frequency in the whole dataset, both training set and testing set\n",
    "  - `judge/products/plots/stat_attributes.pdf`: (discribed in our paper)\n",
    "  - `judge/products/plots/stat_instance_size.pdf`: (discribed in our paper)\n",
    "  - `judge/products/plots/stat_most_freq.pdf`: (discribed in our paper)\n",
    "  - `judge/products/plots/stat_num_char.pdf`: (discribed in our paper)\n",
    "  - `judge/products/plots/stat_num_uniq_char.pdf`: (discribed in our paper)\n",
    "\n",
    "Notes:\n",
    "\n",
    "> This step requires network connection to download `SimHei.ttf`, i.e. a Chinese font file. This font file is used in rendering chinese in our statistics, and some other results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../judge && python3 statistics_in_paper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate classification performance\n",
    "\n",
    "In this step, we will output:\n",
    "\n",
    "  - `<stdout>`: classification performance with each of the attributes\n",
    "  - `<stdout>`: classification performance for top-10 most frequent character categories\n",
    "  - `judge/products/plots/cls_precision_by_attr_size_(model_name).pdf`: (discribed in our paper)\n",
    "  - `judge/products/plots/cls_precision_by_model_size.pdf`: performance for each of models and each of sizes\n",
    "  - `judge/products/explore_cls.html`: performance for each of models and each of sizes\n",
    "\n",
    "If you run `classification_perf.py` without command line arguments, it will evaluate all models listed in `cfgs` in `predictions2html.py`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "  > You may result in a higher performance than paper. The reason may be our models are trained on TRAIN+VAL, but you are using validation set as testing set now.\n",
    "  >\n",
    "  > This step requires network connection to download `Chart.min.js` used to generate `explore_cls.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../judge && python3 classification_perf.py alexnet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results of character instances\n",
    "\n",
    "Besides `predictions`, our baseline also write `probabilities` to results to enable showing confidence probabilities for each of the predictions.\n",
    "\n",
    "This step will generate:\n",
    "\n",
    "  - `judge/products/test_cls_cropped.pkl`: a cache file to avoid frequently reading .jpg files\n",
    "  - `judge/products/predictions_compare.html`: (discribed in our paper)\n",
    "\n",
    "If you run `predictions2html.py` without command line arguments, it will evaluate all models listed in `cfgs`.\n",
    "\n",
    "Then, you can browse `judge/products/predictions_compare.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../judge && python3 predictions2html.py alexnet_v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
